<html>
<head>
<title>Taobao Commodity Dataset</title>
<META content="text/html; charset=iso-8859-1" http-equiv=Content-Type>
<style type="text/css">
  body {
	margin-left: 100px;
	margin-top: 20px;
	margin-right: 100px;
	margin-bottom: 20px;
  }
</style> 
<LINK href="style.css" 
type=text/css rel=stylesheet>
</head>

<body>
<h1 align="center"><strong>Taobao Commodity Dataset</strong></h1>
<center><img alt="dataset overview" src="imgs/ImageAndMask.png" width=700px></img></center>
<h2><strong>Data</strong></h2>
<p> This dataset contains 800 commodity images from the shops on the Taobao website. These images including all kinds of clothing with and without human models have complex backgrounds and scenes with large foregrounds.</p>

<h2><strong>Evaluation</strong></h2>
We evaluate serveral state-of-the-art saliency detection methods on this dataset. The precision-recall curve and F-measure curves are plotted in the following figures left and right. 

<h2><strong>Results of the state-of-art methods</strong></h2>
<table align=center>
<tr>
<td>
<center><img alt="Precision Recall" src="imgs/PR.png" width=500px></img></center>
</td>
<td>
<center><img alt="Fmeasure" src="imgs/FMeasure.png" width=500px></img></center>
</td>
</tr>
</table>

<h2><strong>Downloads</strong></h2>
<table align=center>
<tr>
<td>
<p><a href="./Imgs_TCD.zip">TCD Images</a></p>
</td>
<td>
<p> </p>
</td>
<td>
<p> </p>
</td>
<td>
<p> </p>
</td>
<td>
<p> </p>
</td>
<td>
<p><a href="./Mask_TCD.zip">TCD ground truth masks</a></p>
</td>
</tr>
</table>

<h2><strong>References</strong></h2>
  <table border="0">
    <tr>
      <td width="75">DSR</td>
      <td>[1] X. Li, H. Lu, L. Zhang, X. Ruan, and M.H. Yang. &ldquo;<a href="http://ice.dlut.edu.cn/lu/Project/DSR_saliency_iccv13/web_DSR_saliency.html">Saliency Detection via Dense and Sparse Reconstruction</a>,&rdquo; in IEEE ICCV, 2013.</td>
    </tr>
    <tr>
      <td width="75">GC</td>
      <td>[2] M.M. Cheng, J. Warrell, W.Y. Lin, S. Zheng, V. Vineet, and N. Crook. &ldquo;<a href="http://mmcheng.net/effisalobj/">Efficient Salient Region Detection with Soft Image Abstraction</a>,&rdquo; in IEEE ICCV, 2013.</td>
    </tr>
    <tr>
      <td width="75">HS</td>
      <td>[3] Q. Yan, L. Xu, J. Shi, and J. Jia. &ldquo;<a href="http://www.cse.cuhk.edu.hk/~leojia/projects/hsaliency/">Hierarchical Saliency Detection</a>,&rdquo; in IEEE CVPR, 2013, pp. 1155&ndash;1162.</td>
    </tr>
	<tr>
		<td width="45">SF</td>
		<td>[4] F. Perazzi, P. Krahenbuhl, Y. Pritch, and A. Hornung. &ldquo;<a href="http://graphics.ethz.ch/~perazzif/saliency_filters/">Saliency filters: contrast based filtering for salient region detection</a>,&rdquo; in CVPR, 2012, pp. 733&ndash;740. </td>
	</tr>

	<tr>
		<td width="75">HC,RC</td>
		<td>[5] M. Cheng, G. Zhang, N. Mitra, X. Huang, and S. Hu. &ldquo;<a href="http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/">Global contrast based salient region detection</a>,&rdquo; in CVPR, 2011.  </td>
	</tr>

    <tr>
      <td width="75">CA</td>
      <td>[6] S. Goferman, L. Zelnik-Manor, and A. Tal, &ldquo;<a href="http://webee.technion.ac.il/labs/cgm/Computer-Graphics-Multimedia/Software/Saliency/Saliency.html">Context-aware 
        saliency detection</a>,&rdquo; in IEEE CVPR, 2010, pp. 2376&ndash;2383.</td>
    </tr>

    <tr>
      <td width="75">FT</td>
      <td>[7] R. Achanta, S. Hemami, F. Estrada, and S. Susstrunk.&ldquo;<a href="http://ivrgwww.epfl.ch/supplementary_material/RK_CVPR09/index.html">Frequency-tuned salient region detection</a>,&rdquo; in IEEE CVPR, 
        2009, pp. 1597&ndash;1604.</td>
    </tr>

    <tr>
      <td width="75">SR</td>
      <td>[8] X. Hou, and L. Zhang. &ldquo;<a href="http://www.klab.caltech.edu/~xhou/projects/spectralResidual/spectralresidual.html">Saliency detection: A spectral residual 
        approach</a>,&rdquo; in IEEE CVPR, 2007, pp. 1&ndash;8.</td>
    </tr>

    <tr>
      <td width="75">LC</td>
      <td>[9] Y. Zhai and M. Shah, &ldquo;Visual attention detection in video 
        sequences using spatiotemporal cues,&rdquo; in ACM Multimedia, 
        2006, pp. 815&ndash;824.</td>
    </tr>
  </table>

</body>
</html>
